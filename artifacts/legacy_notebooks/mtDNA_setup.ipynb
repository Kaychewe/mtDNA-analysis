{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Genomic Data Analysis: mtDNA Heteroplasmy </h2> \n",
    " \n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    Before you start running this notebook, make sure you are using a Dataproc runtime. To do so,\n",
    "    <ul>\n",
    "        <li>Click on the Jupyter icon on the right-hand side of the screen</li>\n",
    "        <li>Inside Recommended environments, select Hail Genomics Analysis, which creates the computer type Dataproc Cluster</li>\n",
    "        <li>Select reasonable defaults for CPU, RAM, disk and numbers of workers</li>\n",
    "        <li>Click on Next</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "\n",
    "<h3>  Objectives </h3>\n",
    "<br>\n",
    "The All of Us Research Program has released the short read whole genome sequencing (srWGS) SNP / Indel (“small”) variants dataset as a Hail VariantDataset (VDS) in 2025 to reduce the dataset size. Hail has limited functional support for the Hail VariantDataset format, so we recommend researchers subset the Hail VDS and convert it to other file formats, like Hail MatrixTable, PLINK or VCF files for downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "bucket\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Import Hail and Initialize Spark </h3>\n",
    "\n",
    "<ul>\n",
    "    <li>What is Hail?</li>\n",
    "    <li>What is the workspace bucket?</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hail as hl\n",
    "hl.default_reference(new_default_reference=\"GRCh38\")\n",
    "\n",
    "# READ THE DOCS \n",
    "# https://hail.is/\n",
    "# sets the default reference genome to the argument\n",
    "# Hail is built to scale and has first-class support \n",
    "# for multi-dimensional structured data, like the \n",
    "# genomic data in a genome-wide association study (GWAS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm reference contigs \n",
    "hl.get_reference('GRCh38').contigs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Read Hail VDS </h4>\n",
    "\n",
    "We use the environment variable `WGS_VDS_PATH` to load the srWGS Hail VDS.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vds_srwgs_path = os.getenv(\"WGS_VDS_PATH\")\n",
    "vds_srwgs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vds = hl.vds.read_vds(vds_srwgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vds.variant_data.aggregate_rows(\n",
    "    hl.agg.counter(vds.variant_data.locus.contig)\n",
    ")\n",
    "\n",
    "# run to confirm if mtDNA is avaiable \n",
    "# likely need to call variants directly from data \n",
    "# no eggress allowed ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Basics of the VDS </h2>\n",
    "\n",
    "<h4> Basics of the VDS  </h4>\n",
    "\n",
    "A VariantDataset is the Hail implementation of a data structure called the “scalable variant call representation” (SVCR). It has component tables of reference information and variant information.\n",
    "\n",
    "\n",
    "\n",
    "<h2> Reference Data  </h2>\n",
    "<h4>  Reference Data </h4>\n",
    "\n",
    "The reference information contains the sparse matrix of reference blocks, which is keyed only by locus, and contains an END field which denotes the last position included in the current reference block.\n",
    "\n",
    "We can use\n",
    "\n",
    "<ul>\n",
    "    <li> the function vds.reference_data to get the reference information from the VDS, a MatrixTable with only reference block data,\n",
    "    <li> the function count() to get number of rows and columns in the reference block data,\n",
    "    <li> and the function describe() to get all fields in the reference block data.\n",
    "</ul>\n",
    "\n",
    "<h4>  Further Reading </h4>\n",
    "\n",
    "<ul>\n",
    "    <li> Sparse Matrices: https://en.wikipedia.org/wiki/Sparse_matrix\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vds.reference_data.count()\n",
    "\n",
    "# Note output\n",
    "# (2860284724, 414830)\n",
    "# columns are pre-sample, therefore N=414830 samples \n",
    "# rows are 2860284724 ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vds.reference_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>  Variant Data </h2> \n",
    "<h4>  Variant Data </h4> \n",
    "\n",
    "The varaint information contains the sparse matrix of variant data. We can use\n",
    "\n",
    "<ul>\n",
    "<li> the function vds.variant_data to get the reference information from the VDS, a MatrixTable with only variant data,\n",
    "<li> the function count() to get number of rows and columns in the variant data,\n",
    "<li> and the function describe() to get all fields in the variant data. Please refer to the article How the All of Us genomic data are organized to get detailed information about the fields.\n",
    "<ul>\n",
    "This will mainly focus on manipulating the variant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vds.variant_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vds.variant_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_intervals = ['chr1:100M-200M', 'chr16:29.001M-29.002M']\n",
    "\n",
    "# change coordinate to the variant you are interested in\n",
    "# test_intervals = ['chr13:32355250-3235525]\n",
    "# my main interest is chrM \n",
    "# run test cell below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vds = hl.vds.filter_intervals(\n",
    "    vds,\n",
    "    [hl.parse_locus_interval(x,)\n",
    "     for x in test_intervals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vds.variant_data.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li> filtering by chromosome intervals\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_interval_chrM = ['chrM:1-16569']\n",
    "vds = hl.vds.filter_intervals(\n",
    "    vds,\n",
    "    [hl.parse_locus_interval(x,)\n",
    "    for x in test_interval_chrM])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vds.variant_data.count()\n",
    "# why does the following section return 0 intervals, assume 0 is for intervals?\n",
    "# this is a major bottle neck \n",
    "# will review paper methods \n",
    "# skipped for now \\\n",
    "# testing chr1 heteroplasmy with age instead "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li> filtering by chromosome\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vds = hl.vds.filter_chromosomes(vds, keep= [\"chr1\", \"chr16\"])\n",
    "# test if chrM works (likely will not)\n",
    "# work arounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vds.variant_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li> restricting to a single chromosome\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vds = hl.vds.filter_chromosomes(vds, keep= [\"chr16\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vds.variant_data.count()\n",
    "# expecting 446 variants for 414830 samples \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Convert to dense MatrixTable </h2>\n",
    "<h4> Convert to dense MatrixTable </h4>\n",
    "\n",
    "We use the function vds.to_dense_mt to create a single, dense MatrixTable from the split VariantDataset representation.\n",
    "\n",
    "Before converting to a dense MatrixTable, we will tranform and remove some entries to meet the conventional format of a MatrixTable and other file formats like VCF and PLINK.\n",
    "\n",
    "<ul>\n",
    "    <li> Transform Local Allelic Depth (LAD) </li>\n",
    "</ul>\n",
    "    \n",
    "The All of Us VDS uses Local Alleles (LA) which has information for reference alleles and all alternative alleles across all samples in the array. We will need to convert Local Alleles related fields, Local Allele Depth (LAD) and Local Genotypte (LGT) to the Global Allele format fields (AD and GT), which have information for the reference allele and alternative allele for each sample in the array. We will use two diferent functions to convert LAD to AD and LGT to GT.\n",
    "\n",
    "<ul>\n",
    "     <li> Convert LAD to AD using the function annotate_entries and vds.local_to_global\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = vds.variant_data.annotate_entries(AD = hl.vds.local_to_global(vds.variant_data.LAD, \n",
    "                                                                   vds.variant_data.LA, \n",
    "                                                                   n_alleles=hl.len(vds.variant_data.alleles), \n",
    "                                                                   fill_value=0, number='R'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = mt.annotate_entries(GT = hl.vds.lgt_to_gt(mt.LGT, mt.LA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "     <li> Densify the MatrixTable\n",
    "     <li> This step is necessary before performing any dense MatrixTable-related computations, such as computing AC / AF / AN, variant QC, or converting to VCF / PLINK / BGEN files, etc.\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = hl.vds.to_dense_mt(hl.vds.VariantDataset(vds.reference_data, mt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "     <li> Create fields AC / AF / AN\n",
    "     <li> There are no Allele Counts (AC) / Allele Frequency (AF) / Allele Number (AN) in the VDS. We will use the function agg.call_stats to get the AC / AF / AN.\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = mt.annotate_rows(info = hl.agg.call_stats(mt.GT, mt.alleles))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "     <li> Remove unneccessary fields\n",
    "     <li> We will use the function drop to drop fields\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_to_drop_list = ['as_vets','as_vqsr','LAD', 'LGT', 'LA',\n",
    "            'tranche_data', 'truth_sensitivity_snp_threshold', \n",
    "             'truth_sensitivity_indel_threshold','snp_vqslod_threshold','indel_vqslod_threshold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = mt.drop(*(f for f in fields_to_drop_list if f in mt.entry or f in mt.row or f in mt.col or f in mt.globals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_path = f'{bucket}/data/test_hail.mt'\n",
    "# mt.write(out_path, overwrite = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Convert to VCF file </h2>\n",
    "<ul>\n",
    "    <li> The fields AC and AF include info about the reference alleles, which does not comply with the VCF format. We will use the function transmute_rows to remove the first value in the AC and AF fields. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_vcf = mt.transmute_rows(info = mt.info.annotate(AF=mt.info.AF[1:], \n",
    "                                                              AC=mt.info.AC[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the function export_vcf to create a VCF file. We choose tabix as False so we don't create an index file in this step, as it takes a long time to create the index file using Hail. We will use GATK to create an index file to save time and cost.\n",
    "\n",
    "The VCF header will not be filled in properly with the default arguments. We provide a vcf_header.txt file with the path below, which contains the correct header. We use the function get_vcf_metadata to use it for the metadata argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_header = \"gs://fc-secure-ff68a895-e88d-426e-9ae4-b3802c51b53b/data/vcf_header.txt\"\n",
    "metadata = hl.get_vcf_metadata(vcf_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_vcf = f'{bucket}/data/test_vcf.vcf.bgz'\n",
    "hl.export_vcf(mt_vcf, out_vcf, tabix = False, metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with CRAM\n",
    "CRAM are compressed SAM formats and will most likely include mitochondrial reads that can be processed with mtSwirl. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting mtDNA \\\n",
    "# mtSwril will produce "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genomic_location = os.getenv(\"CDR_STORAGE_PATH\")\n",
    "# genomic_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Hail in some of the examples to load the All of Us genomic data, so let's import Hail and initialize Spark.\n",
    "\n",
    "The All of Us genomic data are using hg38 as reference, so we set the default reference \"GRCh38\" while initializing Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hail as hl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hl.default_reference(new_default_reference = \"GRCh38\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil -u $GOOGLE_PROJECT cat gs://fc-aou-datasets-controlled/v8/wgs/cram/manifest.csv | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gsutil -u $GOOGLE_PROJECT cat gs://fc-aou-datasets-controlled/v8/wgs/short_read/snpindel/clinvar/bed/clinvar.ucsc.bed >> clin.bed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gsutil -u $GOOGLE_PROJECT ls gs://fc-aou-datasets-controlled/v8/wgs/short_read/snpindel/clinvar/vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gsutil -u $GOOGLE_PROJECT cat gs://fc-aou-datasets-controlled/v8/wgs/cram/manifest.csv | head -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gsutil -u $GOOGLE_PROJECT ls gs://fc-aou-datasets-controlled/v8/wgs/short_read/snpindel/clinvar/vcf/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gsutil -u $GOOGLE_PROJECT cat gs://fc-aou-datasets-controlled/v8/wgs/short_read/snpindel/clinvar/vcf/0000020064.interval_list | grep -i chrM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gsutil -u $GOOGLE_PROJECT cat gs://fc-aou-datasets-controlled/v8/wgs/short_read/snpindel/clinvar/vcf/0000020311.vcf.bgz | zcat | grep chrM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gsutil -u $GOOGLE_PROJECT ls gs://fc-aou-datasets-controlled/v8/wgs/short_read/snpindel/exome/vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gsutil -u gs://fc-aou-datasets-controlled/v8/wgs/short_read/snpindel/exome/vcf/0000020016.vcf.bgz | zcat | grep chrM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short Read Whole Genome Sequencing \n",
    "####  srWGS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vds_srwgs_path = os.getenv(\"WGS_VDS_PATH\")\n",
    "# vds_srwgs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vds = hl.vds.read_vds(vds_srwgs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A VDS has component tables of reference information and variant information.\n",
    "\n",
    "The reference information contains the sparse matrix of reference blocks, which is keyed only by locus, and contains an END field which denotes the last position included in the current reference block.\n",
    "\n",
    "We can use function vds.reference_data to get the reference information from the VDS, a MatrixTable with only reference block data, the function count() to get number of rows and columns in the reference block data, and the function describe() to get all fields in the reference block data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vds.reference_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vds.reference_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mt = vds.variant_data\n",
    "# mt.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mt_1 = mt.head(1)\n",
    "# mt_1.locus.contig.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mt_1.aggregate_rows(\n",
    "#     hl.agg.collect_as_set(mt_1.locus.contig)\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mt.filter_rows(mt.locus.contig == \"MT\").head(1).rows().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mtM = mt.filter_rows(mt.locus.contig == \"M\")\n",
    "# mtM.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gsutil -u $GOOGLE_PROJECT ls gs://fc-aou-datasets-controlled/v7/wgs/** | grep -i mt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the analysis cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil ls -r $WORKSPACE_BUCKET | grep person_22012003\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# bucket = os.environ[\"WORKSPACE_BUCKET\"]\n",
    "\n",
    "# csv_path = (\n",
    "#     f\"{bucket}/bq_exports/kchewe@researchallofus.org/\"\n",
    "#     \"20260123/person_22012003/person_22012003_000000000000.csv\"\n",
    "# )\n",
    "\n",
    "# print(\"Reading:\", csv_path)\n",
    "\n",
    "# # Read only the person_id column\n",
    "# df = pd.read_csv(csv_path, usecols=[\"person_id\"])\n",
    "\n",
    "# # Write one ID per line (no header)\n",
    "# df[\"person_id\"].astype(str).to_csv(\n",
    "#     \"analysis_ids.txt\",\n",
    "#     index=False,\n",
    "#     header=False\n",
    "# )\n",
    "\n",
    "# # Copy to bucket root\n",
    "# !gsutil cp analysis_ids.txt $WORKSPACE_BUCKET/analysis_ids.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil ls $WORKSPACE_BUCKET/analysis_ids.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hail as hl\n",
    "\n",
    "# ids = hl.import_table(\n",
    "#     f\"{os.environ['WORKSPACE_BUCKET']}/analysis_ids.txt\",\n",
    "#     no_header=True\n",
    "# ).key_by('f0')\n",
    "\n",
    "# ids.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mt = vds.variant_data\n",
    "# mt = mt.filter_cols(hl.is_defined(ids[mt.s]))\n",
    "# mt.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mt_1 = mt.head(1)\n",
    "# mt_1.locus.contig.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mt_1.aggregate_rows(\n",
    "#     hl.agg.collect_as_set(mt_1.locus.contig)\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolate chrM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # what contigs exist \n",
    "# mt.locus.contig.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtM = mtM.annotate_entries(\n",
    "    dp = hl.sum(mtM.AD)\n",
    ")\n",
    "\n",
    "mt_depth = mtM.group_cols_by(mtM.s).aggregate(\n",
    "    mean_chrM_dp = hl.agg.mean(mtM.dp)\n",
    ").cols()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(mt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mt.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mt.locus.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mt.aggregate_rows(\n",
    "#     hl.agg.any(mt.locus.contig == \"MT\")\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mt.aggregate_rows(\n",
    "#     hl.agg.take(mt.locus.contig, 20)\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
